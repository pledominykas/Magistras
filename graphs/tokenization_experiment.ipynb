{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR9CUVF9tTl9"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2aHksnItbpn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXSaOqQAtb5f"
      },
      "outputs": [],
      "source": [
        "opus_dataset_en_lt = load_dataset(\"Helsinki-NLP/opus-100\", \"en-lt\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA91o4CJtgOd"
      },
      "outputs": [],
      "source": [
        "opus_dataset_en_lt = opus_dataset_en_lt.shuffle(seed=99)\n",
        "opus_dataset_en_lt_sample = opus_dataset_en_lt.select(range(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P6QngtDN9Cc"
      },
      "outputs": [],
      "source": [
        "model_names = [\n",
        "    \"ai-forever/mGPT\",\n",
        "    \"EleutherAI/gpt-neo-1.3B\",\n",
        "    \"meta-llama/Llama-3.2-1B\",\n",
        "    \"bigscience/bloomz-1b7\",\n",
        "    \"DAMO-NLP-MT/polylm-1.7b\",\n",
        "    \"utter-project/EuroLLM-1.7B\",\n",
        "    \"openai-community/gpt2-xl\",\n",
        "    \"facebook/opt-1.3b\",\n",
        "    \"stabilityai/stablelm-2-1_6b\",\n",
        "    \"domce20/mGPT-lithuanian-tokenizer\",\n",
        "    \"neurotechnology/Lt-Llama-2-7b-hf\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_QD0srewspv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "tokenizers = [AutoTokenizer.from_pretrained(model_name) for model_name in model_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kew3K5lx300"
      },
      "outputs": [],
      "source": [
        "def add_token_counts(entry, tokenizer, tokenizer_name):\n",
        "  lithuanian_text = entry['translation']['lt']\n",
        "  english_text = entry['translation']['en']\n",
        "\n",
        "  lt_tokens = tokenizer(lithuanian_text).input_ids\n",
        "  en_tokens = tokenizer(english_text).input_ids\n",
        "\n",
        "  return {\n",
        "      f\"{tokenizer_name}_lt_tokens\": len(lt_tokens),\n",
        "      f\"{tokenizer_name}_en_tokens\": len(en_tokens)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OcVRjZ6yJX6"
      },
      "outputs": [],
      "source": [
        "def calculate_tokens(tokenizer, tokenizer_name):\n",
        "  return opus_dataset_en_lt_sample.map(lambda x: add_token_counts(x, tokenizer, tokenizer_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1YfmD3rzw_4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "for tokenizer in tokenizers:\n",
        "  opus_dataset_en_lt_sample = calculate_tokens(tokenizer, tokenizer.name_or_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFBKdI-k1gNF"
      },
      "outputs": [],
      "source": [
        "df = opus_dataset_en_lt_sample.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nFh2Wpl-wEU"
      },
      "outputs": [],
      "source": [
        "df.mean(numeric_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_grouped_bar_chart(df):\n",
        "    # Extracting Lithuanian and English token columns\n",
        "    lt_columns = [col for col in df.columns if col.endswith('_lt_tokens')]\n",
        "    en_columns = [col.replace('_lt_', '_en_') for col in lt_columns]\n",
        "\n",
        "    # Calculating average token counts for sorting by Lithuanian token counts\n",
        "    lt_avgs = df[lt_columns].mean()\n",
        "    sorted_models = lt_avgs.sort_values(ascending=True).index\n",
        "\n",
        "    # Preparing data for plotting\n",
        "    labels = [model.replace('_lt_tokens', '') for model in sorted_models]\n",
        "    lt_counts = [df[model].mean() for model in sorted_models]\n",
        "    en_counts = [df[model.replace('_lt_', '_en_')].mean() for model in sorted_models]\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(24, 14))\n",
        "    x = range(len(labels))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.bar(x, lt_counts, width, label=\"Lithuanian Tokens\", alpha=0.9)\n",
        "    plt.bar([p + width for p in x], en_counts, width, label=\"English Tokens\", color='gray', alpha=0.6)\n",
        "\n",
        "    plt.xlabel(\"Model\", fontsize=14)\n",
        "    plt.ylabel(\"Average Token Count\", fontsize=14)\n",
        "    plt.xticks([p + width / 2 for p in x], labels, rotation=90, fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "    plt.legend(fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage (assuming `df` is your DataFrame)\n",
        "plot_grouped_bar_chart(df)\n"
      ],
      "metadata": {
        "id": "0cYczp4h21v7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "w_eckC5wuJVK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}